{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PYTHON 3\n",
    "\n",
    "## Lecture 05\n",
    "### Юнит-тестирование\n",
    "\n",
    "<img src=\"https://www.eirlab.net/wp-content/uploads/2022/03/python-logo-2.png\" align=\"right\" style=\"height: 200px;\"/>\n",
    "\n",
    "### Schagin Evgenii\n",
    "\n",
    "\n",
    "MIPT 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Should be 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m nums \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28msum\u001b[39m(nums) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m6\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould be 6\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Should be 6"
     ]
    }
   ],
   "source": [
    "nums = [1, 2, 4]\n",
    "\n",
    "assert sum(nums) == 6, \"Should be 6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "В Python встроен модуль **unittest**, который поддерживает автоматизацию тестов, использование общего кода для настройки и завершения тестов, объединение тестов в группы, а также позволяет отделять тесты от фреймворка для вывода информации.\n",
    "\n",
    "Для автоматизации тестов, unittest поддерживает некоторые важные концепции:\n",
    "\n",
    "**Испытательный стенд (test fixture)** - выполняется подготовка, необходимая для выполнения тестов и все необходимые действия для очистки после выполнения тестов. Это может включать, например, создание временных баз данных или запуск серверного процесса.\n",
    "\n",
    "**Тестовый случай (test case)** - минимальный блок тестирования. Он проверяет ответы для разных наборов данных. Модуль unittest предоставляет базовый класс **TestCase**, который можно использовать для создания новых тестовых случаев.\n",
    "\n",
    "**Набор тестов (test suite)** - несколько тестовых случаев, наборов тестов или и того и другого. Он используется для объединения тестов, которые должны быть выполнены вместе.\n",
    "\n",
    "**Исполнитель тестов (test runner)** - компонент, который управляет выполнением тестов и предоставляет пользователю результат. Исполнитель может использовать графический или текстовый интерфейс или возвращать специальное значение, которое сообщает о результатах выполнения тестов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E\n",
      "======================================================================\n",
      "ERROR: /home/chupolino17/ (unittest.loader._FailedTest)\n",
      "----------------------------------------------------------------------\n",
      "AttributeError: module '__main__' has no attribute '/home/chupolino17/'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.003s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py:3441: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#Простой пример проверки работы строковых методов\n",
    "\n",
    "import unittest\n",
    "\n",
    "class TestStringMethods(unittest.TestCase):\n",
    "    # тестовые методы должны начинаться с test\n",
    "    def test_upper(self):\n",
    "        self.assertEqual('foo'.upper(), 'FOO')\n",
    "\n",
    "    def test_isupper(self):\n",
    "        self.assertTrue('FOO'.isupper())\n",
    "        self.assertFalse('Foo'.isupper())\n",
    "\n",
    "    def test_split(self):\n",
    "        s = 'hello world'\n",
    "        self.assertEqual(s.split(), ['hello', 'world'])\n",
    "        # Проверим, что s.split не работает, если разделитель - не строка\n",
    "        with self.assertRaises(TypeError):\n",
    "            s.split(2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Сохраним код на будущее\n",
    "\n",
    "def dump_to(path):\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(_i)  # _i это \"последний выполненный Input\" в iPython\n",
    "\n",
    "dump_to('strings.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Упс.. Подружим unittest с jupyter notebook:\n",
    "\n",
    "Q: А что случилось?\n",
    "\n",
    "A: Причина в том, что unittest.main просматривает sys.argv, а первый параметр - это то, что запускало Python или Jupiter, поэтому ошибка о том, что файл подключения к ядру не является допустимым атрибутом. Передача явного списка в unittest.main не позволит Python и Jupiter просматривать sys.argv. Передача exit=False не позволит unittest.main завершить процесс ядра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.007s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "#Простой пример проверки работы строковых методов\n",
    "\n",
    "class TestStringMethods(unittest.TestCase):\n",
    "    # тестовые методы должны начинаться с test\n",
    "    def test_upper(self):\n",
    "        self.assertEqual('foo'.upper(), 'FOO')\n",
    "\n",
    "    def test_isupper(self):\n",
    "        self.assertTrue('FOO'.isupper())\n",
    "        self.assertFalse('Foo'.isupper())\n",
    "\n",
    "    def test_split(self):\n",
    "        s = 'hello world'\n",
    "        self.assertEqual(s.split(), ['hello', 'world'])\n",
    "        # Проверим, что s.split не работает, если разделитель - не строка\n",
    "        with self.assertRaises(TypeError):\n",
    "            s.split(2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Интерфейс командной строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.000s\n",
      "\n",
      "OK\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.000s\n",
      "\n",
      "OK\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest strings                               # модуль\n",
    "!python3 -m unittest strings.TestStringMethods             # класс\n",
    "!python3 -m unittest strings.TestStringMethods.test_split  # метод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strings (unittest.loader._FailedTest) ... ERROR\n",
      "\n",
      "======================================================================\n",
      "ERROR: strings (unittest.loader._FailedTest)\n",
      "----------------------------------------------------------------------\n",
      "ImportError: Failed to import test module: strings\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/unittest/loader.py\", line 154, in loadTestsFromName\n",
      "    module = __import__(module_name)\n",
      "ModuleNotFoundError: No module named 'strings'\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    }
   ],
   "source": [
    "#С помощью флага -v можно получить более детальный отчёт:\n",
    "!python3 -m unittest -v strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Ещё флаги:\n",
    "\n",
    "-b (--buffer) - вывод программы при провале теста будет показан, а не скрыт, как обычно.\n",
    "\n",
    "-c (--catch) - Ctrl+C во время выполнения теста ожидает завершения текущего теста и затем сообщает результаты на данный момент. Второе нажатие Ctrl+C вызывает обычное исключение KeyboardInterrupt.\n",
    "\n",
    "-f (--failfast) - выход после первого же неудачного теста.\n",
    "\n",
    "--locals (начиная с Python 3.5) - показывать локальные переменные для провалившихся тестов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Обнаружение тестов\n",
    "\n",
    "unittest поддерживает простое обнаружение тестов. Для совместимости с обнаружением тестов, все файлы тестов должны быть модулями или пакетами, импортируемыми из директории верхнего уровня проекта ([см. подробнее о правилах наименования модулей](https://pythonworld.ru/osnovy/rabota-s-modulyami-sozdanie-podklyuchenie-instrukciyami-import-i-from.html#id3 \"\")).\n",
    "\n",
    "Обнаружение тестов реализовано в TestLoader.discover(), но может быть использовано из командной строки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat 'strings.py': No such file or directory\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 0 tests in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!mv strings.py test_strings.py  #чтобы сработало переименуем модуль в test....py\n",
    "!python3 -m  unittest  discover\n",
    "\n",
    "#-v (--verbose) - подробный вывод.\n",
    "#-s (--start-directory) directory_name - директория начала обнаружения тестов (текущая по умолчанию).\n",
    "#-p (--pattern) pattern - шаблон названия файлов с тестами (по умолчанию test*.py).\n",
    "#-t (--top-level-directory) directory_name - директория верхнего уровня проекта (по умолчанию равна start-directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function discover in module unittest.loader:\n",
      "\n",
      "discover(self, start_dir, pattern='test*.py', top_level_dir=None)\n",
      "    Find and return all test modules from the specified start\n",
      "    directory, recursing into subdirectories to find them and return all\n",
      "    tests found within them. Only test files that match the pattern will\n",
      "    be loaded. (Using shell style pattern matching.)\n",
      "    \n",
      "    All test modules must be importable from the top level of the project.\n",
      "    If the start directory is not the top level directory then the top\n",
      "    level directory must be specified separately.\n",
      "    \n",
      "    If a test package name (directory with '__init__.py') matches the\n",
      "    pattern then the package will be checked for a 'load_tests' function. If\n",
      "    this exists then it will be called with (loader, tests, pattern) unless\n",
      "    the package has already had load_tests called from the same discovery\n",
      "    invocation, in which case the package module object is not scanned for\n",
      "    tests - this ensures that when a package uses discover to further\n",
      "    discover child tests that infinite recursion does not happen.\n",
      "    \n",
      "    If load_tests exists then discovery does *not* recurse into the package,\n",
      "    load_tests is responsible for loading all tests in the package.\n",
      "    \n",
      "    The pattern is deliberately not stored as a loader attribute so that\n",
      "    packages can continue discovery themselves. top_level_dir is stored so\n",
      "    load_tests does not need to pass this argument in to loader.discover().\n",
      "    \n",
      "    Paths are sorted before being imported to ensure reproducible execution\n",
      "    order even on filesystems with non-alphabetical ordering like ext3/4.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from unittest import TestLoader\n",
    "help(TestLoader.discover)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Организация тестового кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим класс, который будем тестировать\n",
    "\n",
    "class Widget():\n",
    "\n",
    "    def __init__(self, name, x = 50, y = 50):\n",
    "\n",
    "        self.name = name\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def size(self):\n",
    "\n",
    "        return (self.x, self.y)\n",
    "\n",
    "    def resize(self, x, y):\n",
    "\n",
    "        # заведомая ошибка, которую надо поймать тестами\n",
    "        self.x = y\n",
    "        self.y = x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Базовые блоки тестирования это тестовые случаи - простые случаи, которые должны быть проверены на корректность.\n",
    "\n",
    "Тестовый случай создаётся путём наследования от unittest.TestCase.\n",
    "\n",
    "Тестирующий код должен быть самостоятельным, то есть никак не зависеть от других тестов.\n",
    "\n",
    "Простейший подкласс TestCase может просто реализовывать тестовый метод (метод, начинающийся с test)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f655c15a2b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class DefaultWidgetSizeTestCase(unittest.TestCase):\n",
    "    def test_default_widget_size(self):\n",
    "        widget = Widget('The widget')\n",
    "        self.assertEqual(widget.size(), (50, 50))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    unittest.main(argv=['',], defaultTest='DefaultWidgetSizeTestCase', exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Тестов может быть много, и часть кода настройки может повторяться. К счастью, мы можем определить код настройки путём реализации метода **setUp()**, который будет запускаться _перед_ каждым тестом.\n",
    "\n",
    "Мы также можем определить метод **tearDown()**, который будет запускаться _после_ каждого теста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".F"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up testcase\n",
      "End of testcase\n",
      "Setting up testcase\n",
      "End of testcase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FAIL: test_widget_resize (__main__.SimpleWidgetTestCase)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/tmp/ipykernel_2031462/3076270793.py\", line 12, in test_widget_resize\n",
      "    self.assertEqual(self.widget.size(), (100,150),\n",
      "AssertionError: Tuples differ: (150, 100) != (100, 150)\n",
      "\n",
      "First differing element 0:\n",
      "150\n",
      "100\n",
      "\n",
      "- (150, 100)\n",
      "+ (100, 150) : wrong size after resize\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.002s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f655c1863d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class SimpleWidgetTestCase(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        print('Setting up testcase')\n",
    "        self.widget = Widget('The widget')\n",
    "\n",
    "    def test_default_widget_size(self):\n",
    "        self.assertEqual(self.widget.size(), (50,50),\n",
    "                         'incorrect default size')\n",
    "\n",
    "    def test_widget_resize(self):\n",
    "        self.widget.resize(100,150)\n",
    "        self.assertEqual(self.widget.size(), (100,150),\n",
    "                         'wrong size after resize')\n",
    "\n",
    "    def tearDown(self):\n",
    "        print('End of testcase')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    unittest.main(argv=['',], defaultTest='SimpleWidgetTestCase', exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "А теперь мы хотим, чтобы инициализация и код подчищающий тесты был общий на все тесткейсы, чтобы сэкономить время тестирования. Добавим __setUpClass__ и __tearDownClass__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".F"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up class\n",
      "End of class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FAIL: test_widget_resize (__main__.SimpleClassSetupWidgetTestCase)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/tmp/ipykernel_2031462/147112305.py\", line 13, in test_widget_resize\n",
      "    self.assertEqual(self.widget.size(), (100,150),\n",
      "AssertionError: Tuples differ: (150, 100) != (100, 150)\n",
      "\n",
      "First differing element 0:\n",
      "150\n",
      "100\n",
      "\n",
      "- (150, 100)\n",
      "+ (100, 150) : wrong size after resize\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f655c186340>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleClassSetupWidgetTestCase(unittest.TestCase):\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        print('Setting up class')\n",
    "        cls.widget = Widget('The widget')\n",
    "\n",
    "    def test_default_widget_size(self):\n",
    "        self.assertEqual(self.widget.size(), (50,50),\n",
    "                         'incorrect default size')\n",
    "\n",
    "    def test_widget_resize(self):\n",
    "        self.widget.resize(100,150)\n",
    "        self.assertEqual(self.widget.size(), (100,150),\n",
    "                         'wrong size after resize')\n",
    "    @classmethod\n",
    "    def tearDownClass(cls):\n",
    "        print('End of class')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    unittest.main(argv=['',], defaultTest='SimpleClassSetupWidgetTestCase', exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Можно разместить все тесты в том же файле, что и сама программа (таком как widgets.py), но размещение тестов в отдельном файле (таком как test_widget.py) имеет много преимуществ:\n",
    "\n",
    "- Модуль с тестом может быть запущен автономно из командной строки.\n",
    "- Тестовый код может быть легко отделён от программы.\n",
    "- Меньше искушения изменить тесты для соответствия коду программы без видимой причины.\n",
    "- Тестовый код должен изменяться гораздо реже, чем программа.\n",
    "- Протестированный код может быть легче переработан.\n",
    "- Тесты для модулей на C должны быть в отдельных модулях, так почему же не быть последовательным?\n",
    "- Если стратегия тестирования изменяется, нет необходимости изменения кода программы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Пропуск тестов и ожидаемые ошибки\n",
    "\n",
    "unittest поддерживает пропуск отдельных тестов, а также классов тестов. Вдобавок, поддерживается пометка теста как \"не работает, но так и надо\".\n",
    "\n",
    "Пропуск теста осуществляется использованием декоратора **skip()** или одного из его условных вариантов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_format (__main__.MyTestCase) ... skipped 'not supported in this library version'\n",
      "test_nothing (__main__.MyTestCase) ... skipped 'demonstrating skipping'\n",
      "test_windows_support (__main__.MyTestCase) ... skipped 'requires Windows'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.002s\n",
      "\n",
      "OK (skipped=3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f655c186880>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "__version__ = (0, 9)\n",
    "platform = \"ubuntu\"\n",
    "\n",
    "\n",
    "class MyTestCase(unittest.TestCase):\n",
    "\n",
    "    @unittest.skip(\"demonstrating skipping\")\n",
    "    def test_nothing(self):\n",
    "        self.fail(\"shouldn't happen\")\n",
    "\n",
    "    @unittest.skipIf(__version__ < (1, 3),\n",
    "                     \"not supported in this library version\")\n",
    "    def test_format(self):\n",
    "        # Tests that work for only a certain version of the library.\n",
    "        pass\n",
    "\n",
    "    @unittest.skipUnless(platform.startswith(\"win\"), \"requires Windows\")\n",
    "    def test_windows_support(self):\n",
    "        # windows specific testing code\n",
    "        pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    unittest.main(argv=['','-v'], defaultTest='MyTestCase', exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Классы также могут быть пропущены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_not_run (__main__.MySkippedTestCase) ... skipped 'showing class skipping'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f655c15ac40>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@unittest.skip(\"showing class skipping\")\n",
    "class MySkippedTestCase(unittest.TestCase):\n",
    "    def test_not_run(self):\n",
    "        pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    unittest.main(argv=['','-v'], defaultTest='MySkippedTestCase', exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Ожидаемые ошибки используют декоратор expectedFailure():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_fail (__main__.ExpectedFailureTestCase) ... expected failure\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK (expected failures=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f655c13d550>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ExpectedFailureTestCase(unittest.TestCase):\n",
    "    @unittest.expectedFailure\n",
    "    def test_fail(self):\n",
    "        self.assertEqual(1, 0, \"broken\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    unittest.main(argv=['','-v'], defaultTest='ExpectedFailureTestCase', exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Очень просто сделать свой декоратор. Например, следующий декоратор пропускает тест, если переданный объект не имеет указанного атрибута."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_fail (__main__.YetAnotherTestCase) ... skipped \"[1, 2, 3] doesn't have 'add'\"\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f655c1515b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj1 = [1, 2, 3]\n",
    "\n",
    "\n",
    "def skipUnlessHasattr(obj, attr):\n",
    "    if hasattr(obj, attr):\n",
    "        return lambda func: func\n",
    "    return unittest.skip(\"{!r} doesn't have {!r}\".format(obj, attr))\n",
    "\n",
    "\n",
    "class YetAnotherTestCase(unittest.TestCase):\n",
    "    @skipUnlessHasattr(obj1,'add')\n",
    "    def test_fail(self):\n",
    "        pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    unittest.main(argv=['','-v'], defaultTest='YetAnotherTestCase', exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Различение итераций теста с помощью подтестов\n",
    "\n",
    "Когда некоторые тесты имеют лишь незначительные отличия, например некоторые параметры, unittest позволяет различать их внутри одного тестового метода, используя менеджер контекста **subTest()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_even (__main__.NumbersTest)\n",
      "Test that numbers between 0 and 3 are all even. ... \n",
      "======================================================================\n",
      "FAIL: test_even (__main__.NumbersTest) (i=1)\n",
      "Test that numbers between 0 and 3 are all even.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/tmp/ipykernel_2031462/3410530980.py\", line 9, in test_even\n",
      "    self.assertEqual(i % 2, 0)\n",
      "AssertionError: 1 != 0\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_even (__main__.NumbersTest) (i=3)\n",
      "Test that numbers between 0 and 3 are all even.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/tmp/ipykernel_2031462/3410530980.py\", line 9, in test_even\n",
      "    self.assertEqual(i % 2, 0)\n",
      "AssertionError: 1 != 0\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f655c151970>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NumbersTest(unittest.TestCase):\n",
    "\n",
    "    def test_even(self):\n",
    "        \"\"\"\n",
    "        Test that numbers between 0 and 3 are all even.\n",
    "        \"\"\"\n",
    "        for i in range(0, 4):\n",
    "            with self.subTest(i=i):\n",
    "                self.assertEqual(i % 2, 0)\n",
    "\n",
    "unittest.main(argv=['','-v'], defaultTest='NumbersTest', exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Есть для подбных целей более элегантное средство..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.yandex-team.ru/simple/\n",
      "Requirement already satisfied: parameterized in /home/chupolino17/.local/lib/python3.8/site-packages (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install parameterized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_sequence_0_foo (__main__.TestSequence) ... ok\n",
      "test_sequence_1_bar (__main__.TestSequence) ... FAIL\n",
      "test_sequence_2_lee (__main__.TestSequence) ... ok\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_sequence_1_bar (__main__.TestSequence)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chupolino17/.local/lib/python3.8/site-packages/parameterized/parameterized.py\", line 620, in standalone_func\n",
      "    return func(*(a + p.args), **p.kwargs, **kw)\n",
      "  File \"/var/tmp/ipykernel_2031462/3644253360.py\", line 11, in test_sequence\n",
      "    self.assertEqual(a,b)\n",
      "AssertionError: 'a' != 'b'\n",
      "- a\n",
      "+ b\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.002s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f655c0acd00>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from parameterized import parameterized\n",
    "\n",
    "class TestSequence(unittest.TestCase):\n",
    "\n",
    "    @parameterized.expand([\n",
    "        [\"foo\", \"a\", \"a\",],\n",
    "        [\"bar\", \"a\", \"b\"],\n",
    "        [\"lee\", \"b\", \"b\"],\n",
    "    ])\n",
    "    def test_sequence(self, name, a, b):\n",
    "        self.assertEqual(a,b)\n",
    "\n",
    "unittest.main(argv=['','-v'], defaultTest='TestSequence', exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Проверки на успешность\n",
    "\n",
    "Модуль unittest предоставляет множество функций для самых различных проверок:\n",
    "\n",
    "```\n",
    "assertEqual(a, b) — a == b\n",
    "\n",
    "assertNotEqual(a, b) — a != b\n",
    "\n",
    "assertTrue(x) — bool(x) is True\n",
    "\n",
    "assertFalse(x) — bool(x) is False\n",
    "\n",
    "assertIs(a, b) — a is b\n",
    "\n",
    "assertIsNot(a, b) — a is not b\n",
    "\n",
    "assertIsNone(x) — x is None\n",
    "\n",
    "assertIsNotNone(x) — x is not None\n",
    "\n",
    "assertIn(a, b) — a in b\n",
    "\n",
    "assertNotIn(a, b) — a not in b\n",
    "\n",
    "assertIsInstance(a, b) — isinstance(a, b)\n",
    "\n",
    "assertNotIsInstance(a, b) — not isinstance(a, b)\n",
    "\n",
    "assertRaises(exc, fun, *args, **kwds) — fun(*args, **kwds) порождает исключение exc\n",
    "\n",
    "assertRaisesRegex(exc, r, fun, *args, **kwds) — fun(*args, **kwds) порождает исключение exc и сообщение соответствует регулярному выражению r\n",
    "\n",
    "assertWarns(warn, fun, *args, **kwds) — fun(*args, **kwds) порождает предупреждение\n",
    "\n",
    "assertWarnsRegex(warn, r, fun, *args, **kwds) — fun(*args, **kwds) порождает предупреждение и сообщение соответствует регулярному выражению r\n",
    "\n",
    "assertAlmostEqual(a, b) — round(a-b, 7) == 0\n",
    "\n",
    "assertNotAlmostEqual(a, b) — round(a-b, 7) != 0\n",
    "\n",
    "assertGreater(a, b) — a > b\n",
    "\n",
    "assertGreaterEqual(a, b) — a >= b\n",
    "\n",
    "assertLess(a, b) — a < b\n",
    "\n",
    "assertLessEqual(a, b) — a <= b\n",
    "\n",
    "assertRegex(s, r) — r.search(s)\n",
    "\n",
    "assertNotRegex(s, r) — not r.search(s)\n",
    "\n",
    "assertCountEqual(a, b) — a и b содержат те же элементы в одинаковых количествах, но порядок не важен\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Если мы хотим кастомизировать запуск имеющихся тестов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_default_widget_size (__main__.SimpleWidgetTestCase) ... ok\n",
      "test_widget_resize (__main__.SimpleWidgetTestCase) ... FAIL\n",
      "test_even (__main__.NumbersTest)\n",
      "Test that numbers between 0 and 3 are all even. ... test_fail (__main__.YetAnotherTestCase) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up testcase\n",
      "End of testcase\n",
      "Setting up testcase\n",
      "End of testcase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipped \"[1, 2, 3] doesn't have 'add'\"\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_widget_resize (__main__.SimpleWidgetTestCase)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/tmp/ipykernel_2031462/3076270793.py\", line 12, in test_widget_resize\n",
      "    self.assertEqual(self.widget.size(), (100,150),\n",
      "AssertionError: Tuples differ: (150, 100) != (100, 150)\n",
      "\n",
      "First differing element 0:\n",
      "150\n",
      "100\n",
      "\n",
      "- (150, 100)\n",
      "+ (100, 150) : wrong size after resize\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_even (__main__.NumbersTest) (i=1)\n",
      "Test that numbers between 0 and 3 are all even.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/tmp/ipykernel_2031462/3410530980.py\", line 9, in test_even\n",
      "    self.assertEqual(i % 2, 0)\n",
      "AssertionError: 1 != 0\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_even (__main__.NumbersTest) (i=3)\n",
      "Test that numbers between 0 and 3 are all even.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/tmp/ipykernel_2031462/3410530980.py\", line 9, in test_even\n",
      "    self.assertEqual(i % 2, 0)\n",
      "AssertionError: 1 != 0\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.004s\n",
      "\n",
      "FAILED (failures=3, skipped=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=4 errors=0 failures=3>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def MySuite():\n",
    "    suite = unittest.TestSuite()\n",
    "    suite.addTest(SimpleWidgetTestCase('test_default_widget_size'))\n",
    "    suite.addTest(SimpleWidgetTestCase('test_widget_resize'))\n",
    "    suite.addTest(NumbersTest('test_even'))\n",
    "    suite.addTest(YetAnotherTestCase('test_fail'))\n",
    "    return suite\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    runner = unittest.TextTestRunner(verbosity=2)\n",
    "    runner.run(MySuite())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
